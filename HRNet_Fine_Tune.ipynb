{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/HRNet/HRNet-Semantic-Segmentation.git /content/HRNet\n",
        "!wget -O hrnet.pth \"https://github.com/hsfzxjy/models.storage/releases/download/HRNet-OCR/hrnet_cs_8090_torch11.pth\""
      ],
      "metadata": {
        "id": "arSsbNQaOH-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-w9CAGhZqjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3991912b-6930-425f-c4ba-f2870a8fa57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs) (6.0.3)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Any, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_HRNET_PATH = \"HRNet_W18_C_ssld_pretrained.pth\"\n",
        "CONFIG_YAML_PATH = \"seg_hrnet_w18_binary_512x512.yaml\""
      ],
      "metadata": {
        "id": "GivvQiAS6Puq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}\n",
        "\n",
        "def is_image(path):\n",
        "    if os.path.splitext(path)[1].lower() not in IMAGE_EXTS:\n",
        "        return False\n",
        "    try:\n",
        "        with Image.open(path) as img:\n",
        "            img.verify()\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "images_folder_path = \"New_Labels\"\n",
        "masks_folder_path  = \"New_masks\"\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "def first_image_in_folder(folder):\n",
        "    \"\"\"Return first image path in folder, or None.\"\"\"\n",
        "    for entry in os.scandir(folder):\n",
        "        if entry.is_file() and is_image(entry.path):\n",
        "            return entry.path\n",
        "    return None\n",
        "\n",
        "count = 0\n",
        "for subfolder in os.listdir(images_folder_path):\n",
        "\n",
        "    img_subdir = os.path.join(images_folder_path, subfolder)\n",
        "    mask_subdir = os.path.join(masks_folder_path, subfolder)\n",
        "\n",
        "    if not os.path.isdir(img_subdir):\n",
        "        continue\n",
        "\n",
        "    count+=1\n",
        "\n",
        "    print(\"Processing image:\", count)\n",
        "\n",
        "    img_paths = [entry.path for entry in os.scandir(img_subdir)\n",
        "                 if entry.is_file() and is_image(entry.path)]\n",
        "\n",
        "    for p in img_paths:\n",
        "        X.append(cv2.imread(p))\n",
        "\n",
        "    if len(img_paths) == 0:\n",
        "        continue\n",
        "\n",
        "    ref_img = cv2.imread(img_paths[0])\n",
        "    H, W = ref_img.shape[:2]\n",
        "\n",
        "    labels_tensor = np.zeros((H, W), dtype=bool)\n",
        "\n",
        "    mask_paths = glob(os.path.join(mask_subdir, \"**/*.npy\"), recursive=True)\n",
        "\n",
        "    for mp in mask_paths:\n",
        "        m = np.load(mp)\n",
        "        labels_tensor |= (m.astype(bool))\n",
        "\n",
        "    Y.append(labels_tensor)\n"
      ],
      "metadata": {
        "id": "GUBzGQ12eP_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea57dfe3-2fcb-43b7-c6d8-80b6afb719f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 1\n",
            "Processing: 2\n",
            "Processing: 3\n",
            "Processing: 4\n",
            "Processing: 5\n",
            "Processing: 6\n",
            "Processing: 7\n",
            "Processing: 8\n",
            "Processing: 9\n",
            "Processing: 10\n",
            "Processing: 11\n",
            "Processing: 12\n",
            "Processing: 13\n",
            "Processing: 14\n",
            "Processing: 15\n",
            "Processing: 16\n",
            "Processing: 17\n",
            "Processing: 18\n",
            "Processing: 19\n",
            "Processing: 20\n",
            "Processing: 21\n",
            "Processing: 22\n",
            "Processing: 23\n",
            "Processing: 24\n",
            "Processing: 25\n",
            "Processing: 26\n",
            "Processing: 27\n",
            "Processing: 28\n",
            "Processing: 29\n",
            "Processing: 30\n",
            "Processing: 31\n",
            "Processing: 32\n",
            "Processing: 33\n",
            "Processing: 34\n",
            "Processing: 35\n",
            "Processing: 36\n",
            "Processing: 37\n",
            "Processing: 38\n",
            "Processing: 39\n",
            "Processing: 40\n",
            "Processing: 41\n",
            "Processing: 42\n",
            "Processing: 43\n",
            "Processing: 44\n",
            "Processing: 45\n",
            "Processing: 46\n",
            "Processing: 47\n",
            "Processing: 48\n",
            "Processing: 49\n",
            "Processing: 50\n",
            "Processing: 51\n",
            "Processing: 52\n",
            "Processing: 53\n",
            "Processing: 54\n",
            "Processing: 55\n",
            "Processing: 56\n",
            "Processing: 57\n",
            "Processing: 58\n",
            "Processing: 59\n",
            "Processing: 60\n",
            "Processing: 61\n",
            "Processing: 62\n",
            "Processing: 63\n",
            "Processing: 64\n",
            "Processing: 65\n",
            "Processing: 66\n",
            "Processing: 67\n",
            "Processing: 68\n",
            "Processing: 69\n",
            "Processing: 70\n",
            "Processing: 71\n",
            "Processing: 72\n",
            "Processing: 73\n",
            "Processing: 74\n",
            "Processing: 75\n",
            "Processing: 76\n",
            "Processing: 77\n",
            "Processing: 78\n",
            "Processing: 79\n",
            "Processing: 80\n",
            "Processing: 81\n",
            "Processing: 82\n",
            "Processing: 83\n",
            "Processing: 84\n",
            "Processing: 85\n",
            "Processing: 86\n",
            "Processing: 87\n",
            "Processing: 88\n",
            "Processing: 89\n",
            "Processing: 90\n",
            "Processing: 91\n",
            "Processing: 92\n",
            "Processing: 93\n",
            "Processing: 94\n",
            "Processing: 95\n",
            "Processing: 96\n",
            "Processing: 97\n",
            "Processing: 98\n",
            "Processing: 99\n",
            "Processing: 100\n",
            "Processing: 101\n",
            "Processing: 102\n",
            "Processing: 103\n",
            "Processing: 104\n",
            "Processing: 105\n",
            "Processing: 106\n",
            "Processing: 107\n",
            "Processing: 108\n",
            "Processing: 109\n",
            "Processing: 110\n",
            "Processing: 111\n",
            "Processing: 112\n",
            "Processing: 113\n",
            "Processing: 114\n",
            "Processing: 115\n",
            "Processing: 116\n",
            "Processing: 117\n",
            "Processing: 118\n",
            "Processing: 119\n",
            "Processing: 120\n",
            "Processing: 121\n",
            "Processing: 122\n",
            "Processing: 123\n",
            "Processing: 124\n",
            "Processing: 125\n",
            "Processing: 126\n",
            "Processing: 127\n",
            "Processing: 128\n",
            "Processing: 129\n",
            "Processing: 130\n",
            "Processing: 131\n",
            "Processing: 132\n",
            "Processing: 133\n",
            "Processing: 134\n",
            "Processing: 135\n",
            "Processing: 136\n",
            "Processing: 137\n",
            "Processing: 138\n",
            "Processing: 139\n",
            "Processing: 140\n",
            "Processing: 141\n",
            "Processing: 142\n",
            "Processing: 143\n",
            "Processing: 144\n",
            "Processing: 145\n",
            "Processing: 146\n",
            "Processing: 147\n",
            "Processing: 148\n",
            "Processing: 149\n",
            "Processing: 150\n",
            "Processing: 151\n",
            "Processing: 152\n",
            "Processing: 153\n",
            "Processing: 154\n",
            "Processing: 155\n",
            "Processing: 156\n",
            "Processing: 157\n",
            "Processing: 158\n",
            "Processing: 159\n",
            "Processing: 160\n",
            "Processing: 161\n",
            "Processing: 162\n",
            "Processing: 163\n",
            "Processing: 164\n",
            "Processing: 165\n",
            "Processing: 166\n",
            "Processing: 167\n",
            "Processing: 168\n",
            "Processing: 169\n",
            "Processing: 170\n",
            "Processing: 171\n",
            "Processing: 172\n",
            "Processing: 173\n",
            "Processing: 174\n",
            "Processing: 175\n",
            "Processing: 176\n",
            "Processing: 177\n",
            "Processing: 178\n",
            "Processing: 179\n",
            "Processing: 180\n",
            "Processing: 181\n",
            "Processing: 182\n",
            "Processing: 183\n",
            "Processing: 184\n",
            "Processing: 185\n",
            "Processing: 186\n",
            "Processing: 187\n",
            "Processing: 188\n",
            "Processing: 189\n",
            "Processing: 190\n",
            "Processing: 191\n",
            "Processing: 192\n",
            "Processing: 193\n",
            "Processing: 194\n",
            "Processing: 195\n",
            "Processing: 196\n",
            "Processing: 197\n",
            "Processing: 198\n",
            "Processing: 199\n",
            "Processing: 200\n",
            "Processing: 201\n",
            "Processing: 202\n",
            "Processing: 203\n",
            "Processing: 204\n",
            "Processing: 205\n",
            "Processing: 206\n",
            "Processing: 207\n",
            "Processing: 208\n",
            "Processing: 209\n",
            "Processing: 210\n",
            "Processing: 211\n",
            "Processing: 212\n",
            "Processing: 213\n",
            "Processing: 214\n",
            "Processing: 215\n",
            "Processing: 216\n",
            "Processing: 217\n",
            "Processing: 218\n",
            "Processing: 219\n",
            "Processing: 220\n",
            "Processing: 221\n",
            "Processing: 222\n",
            "Processing: 223\n",
            "Processing: 224\n",
            "Processing: 225\n",
            "Processing: 226\n",
            "Processing: 227\n",
            "Processing: 228\n",
            "Processing: 229\n",
            "Processing: 230\n",
            "Processing: 231\n",
            "Processing: 232\n",
            "Processing: 233\n",
            "Processing: 234\n",
            "Processing: 235\n",
            "Processing: 236\n",
            "Processing: 237\n",
            "Processing: 238\n",
            "Processing: 239\n",
            "Processing: 240\n",
            "Processing: 241\n",
            "Processing: 242\n",
            "Processing: 243\n",
            "Processing: 244\n",
            "Processing: 245\n",
            "Processing: 246\n",
            "Processing: 247\n",
            "Processing: 248\n",
            "Processing: 249\n",
            "Processing: 250\n",
            "Processing: 251\n",
            "Processing: 252\n",
            "Processing: 253\n",
            "Processing: 254\n",
            "Processing: 255\n",
            "Processing: 256\n",
            "Processing: 257\n",
            "Processing: 258\n",
            "Processing: 259\n",
            "Processing: 260\n",
            "Processing: 261\n",
            "Processing: 262\n",
            "Processing: 263\n",
            "Processing: 264\n",
            "Processing: 265\n",
            "Processing: 266\n",
            "Processing: 267\n",
            "Processing: 268\n",
            "Processing: 269\n",
            "Processing: 270\n",
            "Processing: 271\n",
            "Processing: 272\n",
            "Processing: 273\n",
            "Processing: 274\n",
            "Processing: 275\n",
            "Processing: 276\n",
            "Processing: 277\n",
            "Processing: 278\n",
            "Processing: 279\n",
            "Processing: 280\n",
            "Processing: 281\n",
            "Processing: 282\n",
            "Processing: 283\n",
            "Processing: 284\n",
            "Processing: 285\n",
            "Processing: 286\n",
            "Processing: 287\n",
            "Processing: 288\n",
            "Processing: 289\n",
            "Processing: 290\n",
            "Processing: 291\n",
            "Processing: 292\n",
            "Processing: 293\n",
            "Processing: 294\n",
            "Processing: 295\n",
            "Processing: 296\n",
            "Processing: 297\n",
            "Processing: 298\n",
            "Processing: 299\n",
            "Processing: 300\n",
            "Processing: 301\n",
            "Processing: 302\n",
            "Processing: 303\n",
            "Processing: 304\n",
            "Processing: 305\n",
            "Processing: 306\n",
            "Processing: 307\n",
            "Processing: 308\n",
            "Processing: 309\n",
            "Processing: 310\n",
            "Processing: 311\n",
            "Processing: 312\n",
            "Processing: 313\n",
            "Processing: 314\n",
            "Processing: 315\n",
            "Processing: 316\n",
            "Processing: 317\n",
            "Processing: 318\n",
            "Processing: 319\n",
            "Processing: 320\n",
            "Processing: 321\n",
            "Processing: 322\n",
            "Processing: 323\n",
            "Processing: 324\n",
            "Processing: 325\n",
            "Processing: 326\n",
            "Processing: 327\n",
            "Processing: 328\n",
            "Processing: 329\n",
            "Processing: 330\n",
            "Processing: 331\n",
            "Processing: 332\n",
            "Processing: 333\n",
            "Processing: 334\n",
            "Processing: 335\n",
            "Processing: 336\n",
            "Processing: 337\n",
            "Processing: 338\n",
            "Processing: 339\n",
            "Processing: 340\n",
            "Processing: 341\n",
            "Processing: 342\n",
            "Processing: 343\n",
            "Processing: 344\n",
            "Processing: 345\n",
            "Processing: 346\n",
            "Processing: 347\n",
            "Processing: 348\n",
            "Processing: 349\n",
            "Processing: 350\n",
            "Processing: 351\n",
            "Processing: 352\n",
            "Processing: 353\n",
            "Processing: 354\n",
            "Processing: 355\n",
            "Processing: 356\n",
            "Processing: 357\n",
            "Processing: 358\n",
            "Processing: 359\n",
            "Processing: 360\n",
            "Processing: 361\n",
            "Processing: 362\n",
            "Processing: 363\n",
            "Processing: 364\n",
            "Processing: 365\n",
            "Processing: 366\n",
            "Processing: 367\n",
            "Processing: 368\n",
            "Processing: 369\n",
            "Processing: 370\n",
            "Processing: 371\n",
            "Processing: 372\n",
            "Processing: 373\n",
            "Processing: 374\n",
            "Processing: 375\n",
            "Processing: 376\n",
            "Processing: 377\n",
            "Processing: 378\n",
            "Processing: 379\n",
            "Processing: 380\n",
            "Processing: 381\n",
            "Processing: 382\n",
            "Processing: 383\n",
            "Processing: 384\n",
            "Processing: 385\n",
            "Processing: 386\n",
            "Processing: 387\n",
            "Processing: 388\n",
            "Processing: 389\n",
            "Processing: 390\n",
            "Processing: 391\n",
            "Processing: 392\n",
            "Processing: 393\n",
            "Processing: 394\n",
            "Processing: 395\n",
            "Processing: 396\n",
            "Processing: 397\n",
            "Processing: 398\n",
            "Processing: 399\n",
            "Processing: 400\n",
            "Processing: 401\n",
            "Processing: 402\n",
            "Processing: 403\n",
            "Processing: 404\n",
            "Processing: 405\n",
            "Processing: 406\n",
            "Processing: 407\n",
            "Processing: 408\n",
            "Processing: 409\n",
            "Processing: 410\n",
            "Processing: 411\n",
            "Processing: 412\n",
            "Processing: 413\n",
            "Processing: 414\n",
            "Processing: 415\n",
            "Processing: 416\n",
            "Processing: 417\n",
            "Processing: 418\n",
            "Processing: 419\n",
            "Processing: 420\n",
            "Processing: 421\n",
            "Processing: 422\n",
            "Processing: 423\n",
            "Processing: 424\n",
            "Processing: 425\n",
            "Processing: 426\n",
            "Processing: 427\n",
            "Processing: 428\n",
            "Processing: 429\n",
            "Processing: 430\n",
            "Processing: 431\n",
            "Processing: 432\n",
            "Processing: 433\n",
            "Processing: 434\n",
            "Processing: 435\n",
            "Processing: 436\n",
            "Processing: 437\n",
            "Processing: 438\n",
            "Processing: 439\n",
            "Processing: 440\n",
            "Processing: 441\n",
            "Processing: 442\n",
            "Processing: 443\n",
            "Processing: 444\n",
            "Processing: 445\n",
            "Processing: 446\n",
            "Processing: 447\n",
            "Processing: 448\n",
            "Processing: 449\n",
            "Processing: 450\n",
            "Processing: 451\n",
            "Processing: 452\n",
            "Processing: 453\n",
            "Processing: 454\n",
            "Processing: 455\n",
            "Processing: 456\n",
            "Processing: 457\n",
            "Processing: 458\n",
            "Processing: 459\n",
            "Processing: 460\n",
            "Processing: 461\n",
            "Processing: 462\n",
            "Processing: 463\n",
            "Processing: 464\n",
            "Processing: 465\n",
            "Processing: 466\n",
            "Processing: 467\n",
            "Processing: 468\n",
            "Processing: 469\n",
            "Processing: 470\n",
            "Processing: 471\n",
            "Processing: 472\n",
            "Processing: 473\n",
            "Processing: 474\n",
            "Processing: 475\n",
            "Processing: 476\n",
            "Processing: 477\n",
            "Processing: 478\n",
            "Processing: 479\n",
            "Processing: 480\n",
            "Processing: 481\n",
            "Processing: 482\n",
            "Processing: 483\n",
            "Processing: 484\n",
            "Processing: 485\n",
            "Processing: 486\n",
            "Processing: 487\n",
            "Processing: 488\n",
            "Processing: 489\n",
            "Processing: 490\n",
            "Processing: 491\n",
            "Processing: 492\n",
            "Processing: 493\n",
            "Processing: 494\n",
            "Processing: 495\n",
            "Processing: 496\n",
            "Processing: 497\n",
            "Processing: 498\n",
            "Processing: 499\n",
            "Processing: 500\n",
            "Processing: 501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BinarySegDataset(Dataset):\n",
        "    \"\"\"\n",
        "    items: list of (image_np, mask_np)\n",
        "      image_np: HxWxC numpy\n",
        "      mask_np : HxW numpy with {0,1}\n",
        "    \"\"\"\n",
        "    def __init__(self, items, transform=None):\n",
        "        self.items = items\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_np, mask_np = self.items[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            out = self.transform(image=image_np, mask=mask_np)\n",
        "            image_np, mask_np = out[\"image\"], out[\"mask\"]\n",
        "\n",
        "        image = torch.from_numpy(image_np).permute(2, 0, 1).float()\n",
        "        mask  = torch.from_numpy(mask_np).long()\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "def pad_collate_fn(batch, pad_value_img=0.0, pad_value_mask=0):\n",
        "    \"\"\"\n",
        "    batch: list of (image, mask)\n",
        "      image: (C,H,W)\n",
        "      mask : (H,W)\n",
        "    returns:\n",
        "      images: (B,C,Hmax,Wmax)\n",
        "      masks : (B,Hmax,Wmax)\n",
        "      sizes : list of original (H,W)\n",
        "    \"\"\"\n",
        "    images, masks = zip(*batch)\n",
        "    sizes = [(img.shape[-2], img.shape[-1]) for img in images]\n",
        "\n",
        "    Hmax = max(h for h, w in sizes)\n",
        "    Wmax = max(w for h, w in sizes)\n",
        "\n",
        "    padded_images = []\n",
        "    padded_masks = []\n",
        "\n",
        "    for img, msk in zip(images, masks):\n",
        "        h, w = img.shape[-2], img.shape[-1]\n",
        "        pad_h = Hmax - h\n",
        "        pad_w = Wmax - w\n",
        "\n",
        "        img_pad = F.pad(img, (0, pad_w, 0, pad_h), value=pad_value_img)\n",
        "        msk_pad = F.pad(msk, (0, pad_w, 0, pad_h), value=pad_value_mask)\n",
        "\n",
        "        padded_images.append(img_pad)\n",
        "        padded_masks.append(msk_pad)\n",
        "\n",
        "    images = torch.stack(padded_images, dim=0)\n",
        "    masks  = torch.stack(padded_masks, dim=0)\n",
        "    return images, masks, sizes\n",
        "\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        \"\"\"\n",
        "        logits: (B,1,H,W)\n",
        "        targets: (B,H,W) {0,1}\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "        targets = targets.unsqueeze(1).float()\n",
        "\n",
        "        num = 2 * (probs * targets).sum(dim=(2, 3))\n",
        "        den = (probs + targets).sum(dim=(2, 3)) + self.eps\n",
        "        dice = 1 - (num / den)\n",
        "        return dice.mean()\n",
        "\n",
        "def load_checkpoint(\n",
        "    model,\n",
        "    ckpt_path: str,\n",
        "    strict: bool = False,\n",
        "    map_location=\"cpu\",\n",
        "    drop_head: bool = True,\n",
        "):\n",
        "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
        "    state_dict = ckpt.get(\"state_dict\", ckpt.get(\"model\", ckpt))\n",
        "\n",
        "    new_state = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "\n",
        "    if drop_head:\n",
        "        head_keys = [\"last_layer.3.weight\", \"last_layer.3.bias\"]\n",
        "\n",
        "        head_keys += [k for k in new_state.keys() if \"aux\" in k or \"classifier\" in k]\n",
        "\n",
        "        removed = []\n",
        "        for k in head_keys:\n",
        "            if k in new_state:\n",
        "                removed.append(k)\n",
        "                new_state.pop(k)\n",
        "\n",
        "        if removed:\n",
        "            print(\"Dropped head keys from checkpoint:\", removed)\n",
        "\n",
        "        model_sd = model.state_dict()\n",
        "        mismatched = []\n",
        "        for k in list(new_state.keys()):\n",
        "            if k in model_sd and new_state[k].shape != model_sd[k].shape:\n",
        "                mismatched.append((k, tuple(new_state[k].shape), tuple(model_sd[k].shape)))\n",
        "                new_state.pop(k)\n",
        "\n",
        "        if mismatched:\n",
        "            print(\"Dropped mismatched keys:\")\n",
        "            for k, shp_ckpt, shp_model in mismatched:\n",
        "                print(f\"  {k}: ckpt {shp_ckpt} vs model {shp_model}\")\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(new_state, strict=strict)\n",
        "    print(f\"Loaded checkpoint: {ckpt_path}\")\n",
        "    if missing:\n",
        "        print(\"Missing keys:\", missing)\n",
        "    if unexpected:\n",
        "        print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "    return ckpt\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    device: str = \"cuda\"\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    epochs: int = 20\n",
        "    grad_clip: float = 1.0\n",
        "    amp: bool = True\n",
        "    bce_weight: float = 1.0\n",
        "    dice_weight: float = 1.0\n",
        "    log_every: int = 20\n",
        "\n",
        "\n",
        "def train_hrnet_binary_seg(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: Optional[DataLoader],\n",
        "    ckpt_path: str,\n",
        "    save_dir: str,\n",
        "    cfg: TrainConfig\n",
        "):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    device = torch.device(cfg.device)\n",
        "    model.to(device)\n",
        "\n",
        "    load_checkpoint(model, ckpt_path, strict=False, map_location=device)\n",
        "\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    for p in model.last_layer.parameters():\n",
        "      p.requires_grad = True\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs)\n",
        "\n",
        "    bce_loss = nn.BCEWithLogitsLoss()\n",
        "    dice_loss = DiceLoss()\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp and device.type == \"cuda\")\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "\n",
        "        if epoch > 5:\n",
        "          for name, p in model.named_parameters():\n",
        "            if \"stage4\" in name or \"last_layer\" in name:\n",
        "                p.requires_grad = True\n",
        "            else:\n",
        "                p.requires_grad = False\n",
        "\n",
        "        for it, batch in enumerate(train_loader):\n",
        "            images, masks, _sizes = batch\n",
        "\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            masks  = masks.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled=cfg.amp and device.type == \"cuda\"):\n",
        "                logits = model(images)\n",
        "                if logits.dim() == 3:\n",
        "                    logits = logits.unsqueeze(1)\n",
        "\n",
        "                if logits.shape[-2:] != masks.shape[-2:]:\n",
        "                    logits = F.interpolate(\n",
        "                        logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "                    )\n",
        "\n",
        "                loss_bce  = bce_loss(logits, masks.unsqueeze(1).float())\n",
        "                loss_dice = dice_loss(logits, masks)\n",
        "                loss = cfg.bce_weight * loss_bce + cfg.dice_weight * loss_dice\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if cfg.grad_clip is not None:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running += loss.item()\n",
        "            if (it + 1) % cfg.log_every == 0:\n",
        "                avg = running / cfg.log_every\n",
        "                print(f\"Epoch {epoch+1}/{cfg.epochs} | iter {it+1}/{len(train_loader)} | loss {avg:.4f}\")\n",
        "                running = 0.0\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        val_loss = None\n",
        "        if val_loader is not None:\n",
        "            val_loss = evaluate(model, val_loader, bce_loss, dice_loss, device)\n",
        "            print(f\"Epoch {epoch+1} validation loss: {val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_val:\n",
        "                best_val = val_loss\n",
        "                torch.save(\n",
        "                    {\"model\": model.state_dict(), \"epoch\": epoch+1, \"val_loss\": val_loss},\n",
        "                    os.path.join(save_dir, \"best.pt\")\n",
        "                )\n",
        "                print(\"Saved best checkpoint.\")\n",
        "\n",
        "        torch.save(\n",
        "            {\"model\": model.state_dict(), \"epoch\": epoch+1, \"val_loss\": val_loss},\n",
        "            os.path.join(save_dir, \"last.pt\")\n",
        "        )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, bce_loss, dice_loss, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    n = 0\n",
        "\n",
        "    for images, masks, _sizes in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        masks  = masks.to(device, non_blocking=True)\n",
        "\n",
        "        logits = model(images)\n",
        "        if logits.dim() == 3:\n",
        "            logits = logits.unsqueeze(1)\n",
        "\n",
        "        if logits.shape[-2:] != masks.shape[-2:]:\n",
        "            logits = F.interpolate(\n",
        "                logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "            )\n",
        "\n",
        "        loss = bce_loss(logits, masks.unsqueeze(1).float()) + dice_loss(logits, masks)\n",
        "\n",
        "        total += loss.item()\n",
        "        n += 1\n",
        "\n",
        "    return total / max(n, 1)\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    images_np: list of numpy images HxWxC\n",
        "    \"\"\"\n",
        "    def __init__(self, images_np, transform=None):\n",
        "        self.images = images_np\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_np = self.images[idx]\n",
        "        if self.transform:\n",
        "            out = self.transform(image=img_np)\n",
        "            img_np = out[\"image\"]\n",
        "\n",
        "        img_t = torch.from_numpy(img_np).permute(2,0,1).float()\n",
        "        return img_t\n",
        "\n",
        "\n",
        "def pad_images_collate_fn(batch, pad_value=0.0):\n",
        "    sizes = [(img.shape[-2], img.shape[-1]) for img in batch]\n",
        "    Hmax = max(h for h, w in sizes)\n",
        "    Wmax = max(w for h, w in sizes)\n",
        "\n",
        "    padded = []\n",
        "    for img in batch:\n",
        "        h, w = img.shape[-2], img.shape[-1]\n",
        "        pad_h, pad_w = Hmax - h, Wmax - w\n",
        "        padded.append(F.pad(img, (0, pad_w, 0, pad_h), value=pad_value))\n",
        "\n",
        "    return torch.stack(padded, dim=0), sizes\n",
        "\n",
        "\n",
        "def load_finetuned(model, ckpt_path, device):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    state_dict = ckpt.get(\"model\", ckpt.get(\"state_dict\", ckpt))\n",
        "    new_state = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "    model.load_state_dict(new_state, strict=False)\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_batch(\n",
        "    model: nn.Module,\n",
        "    images_np: List[np.ndarray],\n",
        "    ckpt_path: str,\n",
        "    device: str = \"cuda\",\n",
        "    batch_size: int = 4,\n",
        "    threshold: float = 0.5,\n",
        "    transform=None\n",
        "):\n",
        "    device = torch.device(device)\n",
        "    model = load_finetuned(model, ckpt_path, device)\n",
        "\n",
        "    ds = InferenceDataset(images_np, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        pin_memory=(device.type==\"cuda\"),\n",
        "        collate_fn=pad_images_collate_fn\n",
        "    )\n",
        "\n",
        "    all_masks = []\n",
        "    all_probs = []\n",
        "\n",
        "    for imgs_pad, sizes in loader:\n",
        "        imgs_pad = imgs_pad.to(device)\n",
        "\n",
        "        logits = model(imgs_pad)\n",
        "        if logits.dim() == 3:\n",
        "            logits = logits.unsqueeze(1)\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        for i, (H, W) in enumerate(sizes):\n",
        "            p = probs[i, 0, :H, :W].cpu().numpy()\n",
        "            all_probs.append(p)\n",
        "            all_masks.append((p >= threshold).astype(np.uint8))\n",
        "\n",
        "    return all_masks, all_probs\n"
      ],
      "metadata": {
        "id": "f59F-WdceMl6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hrnet_backbone_only(model, ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    sd = ckpt.get(\"state_dict\", ckpt.get(\"model\", ckpt))\n",
        "    sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
        "    for k in [\"last_layer.3.weight\", \"last_layer.3.bias\"]:\n",
        "        sd.pop(k, None)\n",
        "    return model.load_state_dict(sd, strict=False)\n"
      ],
      "metadata": {
        "id": "lspIrSmCs56e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"HRNet/lib\")\n",
        "sys.path.append(\"HRNet\")\n",
        "\n",
        "import numpy as np\n",
        "if not hasattr(np, \"int\"):   np.int   = int\n",
        "if not hasattr(np, \"bool\"):  np.bool  = bool\n",
        "if not hasattr(np, \"float\"): np.float = float\n",
        "\n",
        "from argparse import Namespace\n",
        "from config import config, update_config\n",
        "from models.seg_hrnet import HighResolutionNet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "cfg_file = CONFIG_YAML_PATH\n",
        "args = Namespace(cfg=cfg_file, opts=[])\n",
        "update_config(config, args)\n",
        "\n",
        "model = HighResolutionNet(config)\n",
        "\n",
        "old_conv = model.last_layer[3]  # Conv2d(720, 19)\n",
        "model.last_layer[3] = nn.Conv2d(\n",
        "    old_conv.in_channels, 1, kernel_size=1, stride=1, padding=0\n",
        ")\n",
        "\n",
        "pretrained = PRETRAINED_HRNET_PATH\n",
        "ckpt = torch.load(pretrained, map_location=\"cpu\")\n",
        "\n",
        "state_dict = ckpt.get(\"state_dict\", ckpt.get(\"model\", ckpt))\n",
        "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "\n",
        "head_keys = [\"last_layer.3.weight\", \"last_layer.3.bias\"]\n",
        "for k in head_keys:\n",
        "    state_dict.pop(k, None)\n",
        "\n",
        "missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "print(\"Loaded pretrained backbone.\")\n",
        "print(\"Missing keys (expected):\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model ready on\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFQxG8MMmkv",
        "outputId": "0cc76864-b4d2-4d46-8d52-6bef75e5b7dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained backbone.\n",
            "Missing keys (expected): ['last_layer.0.weight', 'last_layer.0.bias', 'last_layer.1.weight', 'last_layer.1.bias', 'last_layer.1.running_mean', 'last_layer.1.running_var', 'last_layer.3.weight', 'last_layer.3.bias']\n",
            "Unexpected keys: ['incre_modules.0.0.conv1.weight', 'incre_modules.0.0.bn1.weight', 'incre_modules.0.0.bn1.bias', 'incre_modules.0.0.bn1.running_mean', 'incre_modules.0.0.bn1.running_var', 'incre_modules.0.0.conv2.weight', 'incre_modules.0.0.bn2.weight', 'incre_modules.0.0.bn2.bias', 'incre_modules.0.0.bn2.running_mean', 'incre_modules.0.0.bn2.running_var', 'incre_modules.0.0.conv3.weight', 'incre_modules.0.0.bn3.weight', 'incre_modules.0.0.bn3.bias', 'incre_modules.0.0.bn3.running_mean', 'incre_modules.0.0.bn3.running_var', 'incre_modules.0.0.downsample.0.weight', 'incre_modules.0.0.downsample.1.weight', 'incre_modules.0.0.downsample.1.bias', 'incre_modules.0.0.downsample.1.running_mean', 'incre_modules.0.0.downsample.1.running_var', 'incre_modules.1.0.conv1.weight', 'incre_modules.1.0.bn1.weight', 'incre_modules.1.0.bn1.bias', 'incre_modules.1.0.bn1.running_mean', 'incre_modules.1.0.bn1.running_var', 'incre_modules.1.0.conv2.weight', 'incre_modules.1.0.bn2.weight', 'incre_modules.1.0.bn2.bias', 'incre_modules.1.0.bn2.running_mean', 'incre_modules.1.0.bn2.running_var', 'incre_modules.1.0.conv3.weight', 'incre_modules.1.0.bn3.weight', 'incre_modules.1.0.bn3.bias', 'incre_modules.1.0.bn3.running_mean', 'incre_modules.1.0.bn3.running_var', 'incre_modules.1.0.downsample.0.weight', 'incre_modules.1.0.downsample.1.weight', 'incre_modules.1.0.downsample.1.bias', 'incre_modules.1.0.downsample.1.running_mean', 'incre_modules.1.0.downsample.1.running_var', 'incre_modules.2.0.conv1.weight', 'incre_modules.2.0.bn1.weight', 'incre_modules.2.0.bn1.bias', 'incre_modules.2.0.bn1.running_mean', 'incre_modules.2.0.bn1.running_var', 'incre_modules.2.0.conv2.weight', 'incre_modules.2.0.bn2.weight', 'incre_modules.2.0.bn2.bias', 'incre_modules.2.0.bn2.running_mean', 'incre_modules.2.0.bn2.running_var', 'incre_modules.2.0.conv3.weight', 'incre_modules.2.0.bn3.weight', 'incre_modules.2.0.bn3.bias', 'incre_modules.2.0.bn3.running_mean', 'incre_modules.2.0.bn3.running_var', 'incre_modules.2.0.downsample.0.weight', 'incre_modules.2.0.downsample.1.weight', 'incre_modules.2.0.downsample.1.bias', 'incre_modules.2.0.downsample.1.running_mean', 'incre_modules.2.0.downsample.1.running_var', 'incre_modules.3.0.conv1.weight', 'incre_modules.3.0.bn1.weight', 'incre_modules.3.0.bn1.bias', 'incre_modules.3.0.bn1.running_mean', 'incre_modules.3.0.bn1.running_var', 'incre_modules.3.0.conv2.weight', 'incre_modules.3.0.bn2.weight', 'incre_modules.3.0.bn2.bias', 'incre_modules.3.0.bn2.running_mean', 'incre_modules.3.0.bn2.running_var', 'incre_modules.3.0.conv3.weight', 'incre_modules.3.0.bn3.weight', 'incre_modules.3.0.bn3.bias', 'incre_modules.3.0.bn3.running_mean', 'incre_modules.3.0.bn3.running_var', 'incre_modules.3.0.downsample.0.weight', 'incre_modules.3.0.downsample.1.weight', 'incre_modules.3.0.downsample.1.bias', 'incre_modules.3.0.downsample.1.running_mean', 'incre_modules.3.0.downsample.1.running_var', 'downsamp_modules.0.0.weight', 'downsamp_modules.0.1.weight', 'downsamp_modules.0.1.bias', 'downsamp_modules.0.1.running_mean', 'downsamp_modules.0.1.running_var', 'downsamp_modules.1.0.weight', 'downsamp_modules.1.1.weight', 'downsamp_modules.1.1.bias', 'downsamp_modules.1.1.running_mean', 'downsamp_modules.1.1.running_var', 'downsamp_modules.2.0.weight', 'downsamp_modules.2.1.weight', 'downsamp_modules.2.1.bias', 'downsamp_modules.2.1.running_mean', 'downsamp_modules.2.1.running_var', 'final_layer.0.weight', 'final_layer.1.weight', 'final_layer.1.bias', 'final_layer.1.running_mean', 'final_layer.1.running_var', 'classifier.weight', 'classifier.bias']\n",
            "Model ready on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "assert len(X) == len(Y)\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "train_items = list(zip(X_train, Y_train))\n",
        "val_items   = list(zip(X_val,   Y_val))\n",
        "\n",
        "train_ds = BinarySegDataset(train_items, transform=None)  # or train_tfms\n",
        "val_ds   = BinarySegDataset(val_items,   transform=None)  # or val_tfms\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=3,\n",
        "    shuffle=True,\n",
        "    num_workers=3,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    num_workers=3,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_collate_fn\n",
        ")\n",
        "\n",
        "cfg = TrainConfig(device=\"cuda\", epochs=30, lr=1e-4)\n",
        "\n",
        "train_hrnet_binary_seg(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    ckpt_path=\"runs_h18/hrnet_18.pt\",\n",
        "    save_dir=\"runs_h18\",\n",
        "    cfg=cfg\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AEXjj-cN5Ps",
        "outputId": "7d0fbc7f-0b2a-4519-d7ea-9ca2583bff77"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped head keys from checkpoint: ['last_layer.3.weight', 'last_layer.3.bias']\n",
            "Loaded checkpoint: /content/runs_h18/best.pt\n",
            "Missing keys: ['last_layer.3.weight', 'last_layer.3.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2753826384.py:204: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp and device.type == \"cuda\")\n",
            "/tmp/ipython-input-2753826384.py:227: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=cfg.amp and device.type == \"cuda\"):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | iter 20/134 | loss 0.0854\n",
            "Epoch 1/30 | iter 40/134 | loss 0.0674\n",
            "Epoch 1/30 | iter 60/134 | loss 0.0710\n",
            "Epoch 1/30 | iter 80/134 | loss 0.0739\n",
            "Epoch 1/30 | iter 100/134 | loss 0.0705\n",
            "Epoch 1/30 | iter 120/134 | loss 0.0658\n",
            "Epoch 1 validation loss: 0.1496\n",
            "Saved best checkpoint.\n",
            "Epoch 2/30 | iter 20/134 | loss 0.0707\n",
            "Epoch 2/30 | iter 40/134 | loss 0.0781\n",
            "Epoch 2/30 | iter 60/134 | loss 0.0705\n",
            "Epoch 2/30 | iter 80/134 | loss 0.0767\n",
            "Epoch 2/30 | iter 100/134 | loss 0.0738\n",
            "Epoch 2/30 | iter 120/134 | loss 0.0688\n",
            "Epoch 2 validation loss: 0.1521\n",
            "Epoch 3/30 | iter 20/134 | loss 0.0751\n",
            "Epoch 3/30 | iter 40/134 | loss 0.0709\n",
            "Epoch 3/30 | iter 60/134 | loss 0.0793\n",
            "Epoch 3/30 | iter 80/134 | loss 0.0734\n",
            "Epoch 3/30 | iter 100/134 | loss 0.0831\n",
            "Epoch 3/30 | iter 120/134 | loss 0.0729\n",
            "Epoch 3 validation loss: 0.1478\n",
            "Saved best checkpoint.\n",
            "Epoch 4/30 | iter 20/134 | loss 0.0787\n",
            "Epoch 4/30 | iter 40/134 | loss 0.0671\n",
            "Epoch 4/30 | iter 60/134 | loss 0.0721\n",
            "Epoch 4/30 | iter 80/134 | loss 0.0747\n",
            "Epoch 4/30 | iter 100/134 | loss 0.0773\n",
            "Epoch 4/30 | iter 120/134 | loss 0.0748\n",
            "Epoch 4 validation loss: 0.1531\n",
            "Epoch 5/30 | iter 20/134 | loss 0.0707\n",
            "Epoch 5/30 | iter 40/134 | loss 0.0782\n",
            "Epoch 5/30 | iter 60/134 | loss 0.0736\n",
            "Epoch 5/30 | iter 80/134 | loss 0.0678\n",
            "Epoch 5/30 | iter 100/134 | loss 0.0779\n",
            "Epoch 5/30 | iter 120/134 | loss 0.0700\n",
            "Epoch 5 validation loss: 0.1459\n",
            "Saved best checkpoint.\n",
            "Epoch 6/30 | iter 20/134 | loss 0.0724\n",
            "Epoch 6/30 | iter 40/134 | loss 0.0754\n",
            "Epoch 6/30 | iter 60/134 | loss 0.0780\n",
            "Epoch 6/30 | iter 80/134 | loss 0.0780\n",
            "Epoch 6/30 | iter 100/134 | loss 0.0656\n",
            "Epoch 6/30 | iter 120/134 | loss 0.0749\n",
            "Epoch 6 validation loss: 0.1553\n",
            "Epoch 7/30 | iter 20/134 | loss 0.0840\n",
            "Epoch 7/30 | iter 40/134 | loss 0.0717\n",
            "Epoch 7/30 | iter 60/134 | loss 0.0910\n",
            "Epoch 7/30 | iter 80/134 | loss 0.0763\n",
            "Epoch 7/30 | iter 100/134 | loss 0.0824\n",
            "Epoch 7/30 | iter 120/134 | loss 0.0748\n",
            "Epoch 7 validation loss: 0.1544\n",
            "Epoch 8/30 | iter 20/134 | loss 0.0769\n",
            "Epoch 8/30 | iter 40/134 | loss 0.0827\n",
            "Epoch 8/30 | iter 60/134 | loss 0.0705\n",
            "Epoch 8/30 | iter 80/134 | loss 0.0838\n",
            "Epoch 8/30 | iter 100/134 | loss 0.0728\n",
            "Epoch 8/30 | iter 120/134 | loss 0.0878\n",
            "Epoch 8 validation loss: 0.1717\n",
            "Epoch 9/30 | iter 20/134 | loss 0.0717\n",
            "Epoch 9/30 | iter 40/134 | loss 0.0774\n",
            "Epoch 9/30 | iter 60/134 | loss 0.0742\n",
            "Epoch 9/30 | iter 80/134 | loss 0.0819\n",
            "Epoch 9/30 | iter 100/134 | loss 0.0856\n",
            "Epoch 9/30 | iter 120/134 | loss 0.0849\n",
            "Epoch 9 validation loss: 0.1639\n",
            "Epoch 10/30 | iter 20/134 | loss 0.0888\n",
            "Epoch 10/30 | iter 40/134 | loss 0.0846\n",
            "Epoch 10/30 | iter 60/134 | loss 0.0774\n",
            "Epoch 10/30 | iter 80/134 | loss 0.0783\n",
            "Epoch 10/30 | iter 100/134 | loss 0.0751\n",
            "Epoch 10/30 | iter 120/134 | loss 0.0755\n",
            "Epoch 10 validation loss: 0.1564\n",
            "Epoch 11/30 | iter 20/134 | loss 0.0739\n",
            "Epoch 11/30 | iter 40/134 | loss 0.0699\n",
            "Epoch 11/30 | iter 60/134 | loss 0.0735\n",
            "Epoch 11/30 | iter 80/134 | loss 0.0763\n",
            "Epoch 11/30 | iter 100/134 | loss 0.0732\n",
            "Epoch 11/30 | iter 120/134 | loss 0.0645\n",
            "Epoch 11 validation loss: 0.1576\n",
            "Epoch 12/30 | iter 20/134 | loss 0.0761\n",
            "Epoch 12/30 | iter 40/134 | loss 0.0676\n",
            "Epoch 12/30 | iter 60/134 | loss 0.0761\n",
            "Epoch 12/30 | iter 80/134 | loss 0.0744\n",
            "Epoch 12/30 | iter 100/134 | loss 0.0678\n",
            "Epoch 12/30 | iter 120/134 | loss 0.0676\n",
            "Epoch 12 validation loss: 0.1596\n",
            "Epoch 13/30 | iter 20/134 | loss 0.0671\n",
            "Epoch 13/30 | iter 40/134 | loss 0.0853\n",
            "Epoch 13/30 | iter 60/134 | loss 0.0693\n",
            "Epoch 13/30 | iter 80/134 | loss 0.0651\n",
            "Epoch 13/30 | iter 100/134 | loss 0.0712\n",
            "Epoch 13/30 | iter 120/134 | loss 0.0693\n",
            "Epoch 13 validation loss: 0.1580\n",
            "Epoch 14/30 | iter 20/134 | loss 0.0728\n",
            "Epoch 14/30 | iter 40/134 | loss 0.0754\n",
            "Epoch 14/30 | iter 60/134 | loss 0.0673\n",
            "Epoch 14/30 | iter 80/134 | loss 0.0626\n",
            "Epoch 14/30 | iter 100/134 | loss 0.0705\n",
            "Epoch 14/30 | iter 120/134 | loss 0.0722\n",
            "Epoch 14 validation loss: 0.1527\n",
            "Epoch 15/30 | iter 20/134 | loss 0.0609\n",
            "Epoch 15/30 | iter 40/134 | loss 0.0784\n",
            "Epoch 15/30 | iter 60/134 | loss 0.0740\n",
            "Epoch 15/30 | iter 80/134 | loss 0.0693\n",
            "Epoch 15/30 | iter 100/134 | loss 0.0693\n",
            "Epoch 15/30 | iter 120/134 | loss 0.0702\n",
            "Epoch 15 validation loss: 0.1618\n",
            "Epoch 16/30 | iter 20/134 | loss 0.0600\n",
            "Epoch 16/30 | iter 40/134 | loss 0.0705\n",
            "Epoch 16/30 | iter 60/134 | loss 0.0745\n",
            "Epoch 16/30 | iter 80/134 | loss 0.0613\n",
            "Epoch 16/30 | iter 100/134 | loss 0.0629\n",
            "Epoch 16/30 | iter 120/134 | loss 0.0672\n",
            "Epoch 16 validation loss: 0.1539\n",
            "Epoch 17/30 | iter 20/134 | loss 0.0610\n",
            "Epoch 17/30 | iter 40/134 | loss 0.0666\n",
            "Epoch 17/30 | iter 60/134 | loss 0.0685\n",
            "Epoch 17/30 | iter 80/134 | loss 0.0671\n",
            "Epoch 17/30 | iter 100/134 | loss 0.0648\n",
            "Epoch 17/30 | iter 120/134 | loss 0.0620\n",
            "Epoch 17 validation loss: 0.1658\n",
            "Epoch 18/30 | iter 20/134 | loss 0.0619\n",
            "Epoch 18/30 | iter 40/134 | loss 0.0707\n",
            "Epoch 18/30 | iter 60/134 | loss 0.0686\n",
            "Epoch 18/30 | iter 80/134 | loss 0.0749\n",
            "Epoch 18/30 | iter 100/134 | loss 0.0605\n",
            "Epoch 18/30 | iter 120/134 | loss 0.0601\n",
            "Epoch 18 validation loss: 0.1463\n",
            "Epoch 19/30 | iter 20/134 | loss 0.0656\n",
            "Epoch 19/30 | iter 40/134 | loss 0.0664\n",
            "Epoch 19/30 | iter 60/134 | loss 0.0616\n",
            "Epoch 19/30 | iter 80/134 | loss 0.0683\n",
            "Epoch 19/30 | iter 100/134 | loss 0.0631\n",
            "Epoch 19/30 | iter 120/134 | loss 0.0696\n",
            "Epoch 19 validation loss: 0.1519\n",
            "Epoch 20/30 | iter 20/134 | loss 0.0646\n",
            "Epoch 20/30 | iter 40/134 | loss 0.0600\n",
            "Epoch 20/30 | iter 60/134 | loss 0.0594\n",
            "Epoch 20/30 | iter 80/134 | loss 0.0624\n",
            "Epoch 20/30 | iter 100/134 | loss 0.0592\n",
            "Epoch 20/30 | iter 120/134 | loss 0.0626\n",
            "Epoch 20 validation loss: 0.1625\n",
            "Epoch 21/30 | iter 20/134 | loss 0.0604\n",
            "Epoch 21/30 | iter 40/134 | loss 0.0687\n",
            "Epoch 21/30 | iter 60/134 | loss 0.0581\n",
            "Epoch 21/30 | iter 80/134 | loss 0.0701\n",
            "Epoch 21/30 | iter 100/134 | loss 0.0653\n",
            "Epoch 21/30 | iter 120/134 | loss 0.0615\n",
            "Epoch 21 validation loss: 0.1492\n",
            "Epoch 22/30 | iter 20/134 | loss 0.0596\n",
            "Epoch 22/30 | iter 40/134 | loss 0.0682\n",
            "Epoch 22/30 | iter 60/134 | loss 0.0582\n",
            "Epoch 22/30 | iter 80/134 | loss 0.0620\n",
            "Epoch 22/30 | iter 100/134 | loss 0.0568\n",
            "Epoch 22/30 | iter 120/134 | loss 0.0604\n",
            "Epoch 22 validation loss: 0.1532\n",
            "Epoch 23/30 | iter 20/134 | loss 0.0601\n",
            "Epoch 23/30 | iter 40/134 | loss 0.0649\n",
            "Epoch 23/30 | iter 60/134 | loss 0.0591\n",
            "Epoch 23/30 | iter 80/134 | loss 0.0662\n",
            "Epoch 23/30 | iter 100/134 | loss 0.0613\n",
            "Epoch 23/30 | iter 120/134 | loss 0.0601\n",
            "Epoch 23 validation loss: 0.1484\n",
            "Epoch 24/30 | iter 20/134 | loss 0.0681\n",
            "Epoch 24/30 | iter 40/134 | loss 0.0672\n",
            "Epoch 24/30 | iter 60/134 | loss 0.0557\n",
            "Epoch 24/30 | iter 80/134 | loss 0.0583\n",
            "Epoch 24/30 | iter 100/134 | loss 0.0538\n",
            "Epoch 24/30 | iter 120/134 | loss 0.0601\n",
            "Epoch 24 validation loss: 0.1543\n",
            "Epoch 25/30 | iter 20/134 | loss 0.0561\n",
            "Epoch 25/30 | iter 40/134 | loss 0.0688\n",
            "Epoch 25/30 | iter 60/134 | loss 0.0597\n",
            "Epoch 25/30 | iter 80/134 | loss 0.0663\n",
            "Epoch 25/30 | iter 100/134 | loss 0.0560\n",
            "Epoch 25/30 | iter 120/134 | loss 0.0580\n",
            "Epoch 25 validation loss: 0.1562\n",
            "Epoch 26/30 | iter 20/134 | loss 0.0603\n",
            "Epoch 26/30 | iter 40/134 | loss 0.0578\n",
            "Epoch 26/30 | iter 60/134 | loss 0.0568\n",
            "Epoch 26/30 | iter 80/134 | loss 0.0602\n",
            "Epoch 26/30 | iter 100/134 | loss 0.0639\n",
            "Epoch 26/30 | iter 120/134 | loss 0.0680\n",
            "Epoch 26 validation loss: 0.1485\n",
            "Epoch 27/30 | iter 20/134 | loss 0.0650\n",
            "Epoch 27/30 | iter 40/134 | loss 0.0642\n",
            "Epoch 27/30 | iter 60/134 | loss 0.0612\n",
            "Epoch 27/30 | iter 80/134 | loss 0.0577\n",
            "Epoch 27/30 | iter 100/134 | loss 0.0572\n",
            "Epoch 27/30 | iter 120/134 | loss 0.0559\n",
            "Epoch 27 validation loss: 0.1587\n",
            "Epoch 28/30 | iter 20/134 | loss 0.0640\n",
            "Epoch 28/30 | iter 40/134 | loss 0.0601\n",
            "Epoch 28/30 | iter 60/134 | loss 0.0646\n",
            "Epoch 28/30 | iter 80/134 | loss 0.0642\n",
            "Epoch 28/30 | iter 100/134 | loss 0.0588\n",
            "Epoch 28/30 | iter 120/134 | loss 0.0580\n",
            "Epoch 28 validation loss: 0.1536\n",
            "Epoch 29/30 | iter 20/134 | loss 0.0542\n",
            "Epoch 29/30 | iter 40/134 | loss 0.0562\n",
            "Epoch 29/30 | iter 60/134 | loss 0.0578\n",
            "Epoch 29/30 | iter 80/134 | loss 0.0698\n",
            "Epoch 29/30 | iter 100/134 | loss 0.0662\n",
            "Epoch 29/30 | iter 120/134 | loss 0.0599\n",
            "Epoch 29 validation loss: 0.1524\n",
            "Epoch 30/30 | iter 20/134 | loss 0.0621\n",
            "Epoch 30/30 | iter 40/134 | loss 0.0626\n",
            "Epoch 30/30 | iter 60/134 | loss 0.0672\n",
            "Epoch 30/30 | iter 80/134 | loss 0.0588\n",
            "Epoch 30/30 | iter 100/134 | loss 0.0591\n",
            "Epoch 30/30 | iter 120/134 | loss 0.0599\n",
            "Epoch 30 validation loss: 0.1532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def save_all_val_predictions(\n",
        "    model,\n",
        "    val_loader,\n",
        "    best_ckpt_path,\n",
        "    save_dir,\n",
        "    threshold=0.5,\n",
        "    device=\"cuda\"\n",
        "):\n",
        "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # ---- load best checkpoint once ----\n",
        "    ckpt = torch.load(best_ckpt_path, map_location=device)\n",
        "    state_dict = ckpt.get(\"model\", ckpt.get(\"state_dict\", ckpt))\n",
        "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    model.to(device).eval()\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    global_idx = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_loader):\n",
        "            images, masks, sizes = batch   # images: (B, C, Hpad, Wpad)\n",
        "            images = images.to(device)\n",
        "\n",
        "            # ---- forward ----\n",
        "            logits = model(images)\n",
        "            if logits.dim() == 3:\n",
        "                logits = logits.unsqueeze(1)\n",
        "\n",
        "            # upsample if needed\n",
        "            if logits.shape[-2:] != masks.shape[-2:]:\n",
        "                logits = F.interpolate(\n",
        "                    logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "                )\n",
        "\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            # ---- per-sample loop ----\n",
        "            for i in range(images.size(0)):\n",
        "                H, W = sizes[i]  # original image size\n",
        "\n",
        "                # ----- save original input image -----\n",
        "                # ----- save original input image (robust float handling) -----\n",
        "                img_t = images[i, :, :H, :W].detach().cpu()   # (C,H,W), float\n",
        "\n",
        "                # If normalized or arbitrary float range, bring to 0..1 safely\n",
        "                img_t = img_t.float()\n",
        "                img_t = img_t - img_t.min()\n",
        "                if img_t.max() > 0:\n",
        "                    img_t = img_t / img_t.max()\n",
        "\n",
        "                img_np = (img_t.numpy() * 255).astype(np.uint8)  # uint8 CHW\n",
        "\n",
        "                # CHW -> HWC for RGB, or squeeze for grayscale\n",
        "                if img_np.shape[0] == 1:\n",
        "                    img_np = img_np[0]  # (H,W)\n",
        "                else:\n",
        "                    img_np = np.transpose(img_np, (1, 2, 0))  # (H,W,C)\n",
        "\n",
        "                img_save_path = os.path.join(save_dir, f\"img{global_idx}.png\")\n",
        "                Image.fromarray(img_np).save(img_save_path)\n",
        "\n",
        "                global_idx += 1\n",
        "\n",
        "    print(f\"Saved {global_idx} images + masks to: {save_dir}\")\n",
        "\n",
        "\n",
        "\n",
        "best_ckpt = \"runs_h18/best.pt\"\n",
        "save_dir = \"runs_h18/val_preds\"\n",
        "\n",
        "save_all_val_predictions(\n",
        "    model=model,\n",
        "    val_loader=val_loader,\n",
        "    best_ckpt_path=best_ckpt,\n",
        "    save_dir=save_dir,\n",
        "    threshold=0.5,\n",
        "    device=cfg.device\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgGbNxze1GjW",
        "outputId": "34e47364-527e-4f3d-a9cc-5055e23f0ff3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 100 images + masks to: /content/runs_h18/val_preds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r validation_masks.zip /content/runs_h18/val_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIcSF06k3F_o",
        "outputId": "8c0c41d8-e1af-4be3-8cb6-c235f232f07b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/runs_h18/val_preds/ (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00077.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00028.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00081.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00062.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00023.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00045.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00090.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00072.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00097.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00036.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00037.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00095.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00078.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00049.png (deflated 21%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00094.png (deflated 18%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00009.png (deflated 11%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00056.png (deflated 20%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00066.png (deflated 9%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00004.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00014.png (deflated 11%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00007.png (deflated 4%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00098.png (deflated 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00055.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00075.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00048.png (deflated 11%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00083.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00054.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00016.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00067.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00005.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00069.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00022.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00038.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00064.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00071.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00087.png (deflated 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00013.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00089.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00080.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00006.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00019.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00060.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00003.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00039.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00025.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00024.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00092.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00032.png (deflated 16%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00018.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00026.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00076.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00033.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00046.png (deflated 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00043.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00015.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00058.png (deflated 11%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00065.png (deflated 7%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00057.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00068.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00000.png (deflated 16%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00030.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00044.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00021.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00053.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00084.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00001.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00099.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00085.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00012.png (deflated 4%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00017.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00050.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00052.png (deflated 6%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00035.png (deflated 8%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00096.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00079.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00063.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00011.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00008.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00040.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00082.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00091.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00034.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00051.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00010.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00061.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00042.png (deflated 4%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00086.png (deflated 1%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00059.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00070.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00088.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00093.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00074.png (deflated 18%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00027.png (deflated 5%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00041.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00047.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00002.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00029.png (deflated 3%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00073.png (deflated 2%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00031.png (stored 0%)\n",
            "updating: content/runs_h18/val_preds/val_pred_00020.png (deflated 6%)\n",
            "  adding: content/runs_h18/val_preds/img74.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img67.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img69.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img11.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img82.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img76.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img55.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img29.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img62.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img9.png (deflated 2%)\n",
            "  adding: content/runs_h18/val_preds/img91.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img37.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img57.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img97.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img81.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img85.png (deflated 2%)\n",
            "  adding: content/runs_h18/val_preds/img28.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img80.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img30.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img36.png (deflated 2%)\n",
            "  adding: content/runs_h18/val_preds/img92.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img86.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img17.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img14.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img72.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img15.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img96.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img88.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img40.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img31.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img22.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img5.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img90.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img4.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img25.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img61.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img21.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img7.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img75.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img94.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img58.png (deflated 3%)\n",
            "  adding: content/runs_h18/val_preds/img52.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img46.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img50.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img20.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img53.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img66.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img78.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img6.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img44.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img3.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img84.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img35.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img95.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img43.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img33.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img87.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img59.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img16.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img1.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img64.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img32.png (deflated 2%)\n",
            "  adding: content/runs_h18/val_preds/img68.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img51.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img89.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img79.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img23.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img18.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img34.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img56.png (deflated 2%)\n",
            "  adding: content/runs_h18/val_preds/img8.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img77.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img27.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img48.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img42.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img0.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img47.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img98.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img63.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img12.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img45.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img38.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img26.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img19.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img24.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img39.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img70.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img93.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img49.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img54.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img60.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img41.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img65.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img73.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img71.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img2.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img13.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img83.png (deflated 0%)\n",
            "  adding: content/runs_h18/val_preds/img10.png (deflated 1%)\n",
            "  adding: content/runs_h18/val_preds/img99.png (deflated 0%)\n"
          ]
        }
      ]
    }
  ]
}